import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report
# Load the dataset
df = pd.read_csv('kddcup.data_10_percent_corrected', header=None)
# Assign column names (for illustration; actual dataset has 41 features)
columns = [f'feature_{i}' for i in range(df.shape[1] - 1)] + ['label']
df.columns = columns
# Encode categorical features
categorical_cols = df.select_dtypes(include=['object']).columns
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
# Separate features and labels
X = df.drop('label', axis=1)
y = df['label'].apply(lambda x: 0 if x == 'normal.' else 1)  # 0: normal, 1: anomaly
# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
# Initialize the model
iso_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)
# Fit the model
iso_forest.fit(X_scaled)
# Predict anomalies
y_pred = iso_forest.predict(X_scaled)
y_pred = np.where(y_pred == 1, 0, 1)  # Convert to 0: normal, 1: anomaly
print(classification_report(y, y_pred, target_names=['Normal', 'Anomaly']))
